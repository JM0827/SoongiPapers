# Environment variables for Project-T1 backend
# NOTE: if your Postgres password contains special chars like '@', they must be percent-encoded in the DATABASE_URL
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/postgres
# Also provide PG_* (used by some helpers) and PG_URI (used by db-init).
PG_HOST=localhost
PG_PORT=5432
PG_USER=postgres
PG_PASSWORD=postgres
PG_DATABASE=postgres
PG_URI=postgresql://postgres:postgres@localhost:5432/postgres

MONGO_URI=mongodb://localhost:27017/project_t1
MONGO_DB=project_t1

# Google OAuth 설정
GOOGLE_CALLBACK_URL=http://soongipapers.com:8080/api/auth/google/callback
OAUTH_SUCCESS_REDIRECT=http://soongipapers.com:5174/oauth/callback
VITE_OAUTH_URL=http://soongipapers.com:8080/api/auth/google
CLIENT_ORIGIN=http://soongipapers.com:5174
# JWT secret for local dev (change before production)
JWT_SECRET=dev_jwt_secret_change_me

# OpenAI API key and model settings
OPENAI_API_KEY=sk-your-openai-api-key

# 기본 임베딩 모델
OPENAI_EMBED_MODEL=text-embedding-3-small

# 기본 대화 모델
CHAT_MODEL=gpt-5-mini
CHAT_VERBOSITY=low # "low" | "medium" | "high"
CHAT_REASONING_EFFORT=low # "low" | "medium" | "high"
CHAT_MAX_OUTPUT_TOKENS=900
CHAT_ENTITY_MODEL=gpt-5-mini
CHAT_ENTITY_VERBOSITY=low
CHAT_ENTITY_EFFORT=minimal
CHAT_ENTITY_MAX_OUTPUT_TOKENS=256
INTENT_CLASSIFIER_MODEL=gpt-5-mini
INTENT_CLASSIFIER_VERBOSITY=low
INTENT_CLASSIFIER_EFFORT=minimal
INTENT_CLASSIFIER_MAX_OUTPUT_TOKENS=256
EDITING_ASSIST_MODEL=gpt-5-mini
EDITING_ASSIST_VERBOSITY=low
EDITING_ASSIST_REASONING_EFFORT=low
EDITING_ASSIST_MAX_OUTPUT_TOKENS=1200

# 원작 분석 담당 모델
PROFILE_AGENT_MODEL=gpt-5-mini
PROFILE_AGENT_VALIDATION_MODEL=gpt-5-mini
PROFILE_AGENT_VERBOSITY=low # "low" | "medium" | "high"
PROFILE_AGENT_REASONING_EFFORT=medium # "low" | "medium" | "high"
PROFILE_AGENT_MAX_OUTPUT_TOKENS=24000
PROFILE_AGENT_CONTEXT_CHAR_LIMIT=20000

# 번역 담당 모델 (초안, 검토, 수정)
# Segmentation
SEGMENTATION_MAX_SEGMENT_LENGTH_V2=1200 # ≈1,500 tokens (평균 3.2 chars/token)
SEGMENTATION_MODE_V2=balanced # "conservative" | "balanced" | "aggressive"
MAX_SEGMENTS_PER_REQUEST=1   # 배치 1로 트렁케이션 리스크 최소화(처리량은 워커 병렬로 보전)
CANONICAL_SEGMENT_BATCH_SIZE=200
CANONICAL_SEGMENT_YIELD_INTERVAL=75  # 이벤트 루프 양보 주기 (세그먼트 수, 0 이하면 비활성화)
CANONICAL_PERSIST_YIELD_EVERY=1      # INSERT chunk 몇 번마다 양보할지 (0 이하면 비활성화)
TRANSLATION_V2_LOCK_DURATION_MS=240000
TRANSLATION_V2_STALLED_INTERVAL_MS=60000
TRANSLATION_V2_MAX_STALLED_COUNT=2
# Draft
TRANSLATION_DRAFT_MODEL_V2=gpt-5-mini
TRANSLATION_DRAFT_VERBOSITY_V2=low # "low" | "medium" | "high"
TRANSLATION_DRAFT_REASONING_EFFORT_V2=medium # "low" | "medium" | "high"
TRANSLATION_DRAFT_MAX_OUTPUT_TOKENS_V2=3600 # 1200자 × 확장 + 스키마 여유
TRANSLATION_DRAFT_MAX_OUTPUT_TOKENS_CAP_V2=7000 # 상한(모델 한도 내)
TRANSLATION_DRAFT_JUDGE_MODEL_V2=gpt-5-mini
TRANSLATION_DRAFT_JUDGE_MAX_OUTPUT_TOKENS_V2=3000 # token ceiling specifically for the judge call.
# Revise
TRANSLATION_REVISE_MODEL_V2=gpt-5
TRANSLATION_REVISE_VALIDATION_MODEL_V2=gpt-5
TRANSLATION_REVISE_VERBOSITY_V2=medium # "low" | "medium" | "high"
TRANSLATION_REVISE_REASONING_EFFORT_V2=low # "low" | "medium" | "high"
TRANSLATION_REVISE_MAX_OUTPUT_TOKENS_V2=3200
TRANSLATION_REVISE_MAX_OUTPUT_TOKENS_CAP_V2=7000

# Observation 모델 설정
TRANSLATION_V2_DEBUG=true # true | false to enable debug logging for translation v2

# 단계 모델 및 설정 메모 (참고용)
# Draft (초안)	gpt-5	medium	high
# Revise (정밀 교정)	gpt-5-pro	high	medium

# 교정 담당 모델 (KO→EN 문학 기준: 안정>품질>비용)
PROOFREADING_MODEL=gpt-5
PROOFREADING_VERBOSITY=medium          # 수정 + 짧은 근거를 받기 위함
PROOFREADING_REASONING_EFFORT=low      # 과도한 장문 설명 방지(Deep 티어에서만 높임)

# 공통 상한 (실제 요청 계산이 이 CAP를 읽도록 보장)
PROOFREADING_MAX_OUTPUT_TOKENS_CAP=7000

# 베이스 한도(티어 미사용 경로 보호)
PROOFREADING_MAX_OUTPUT_TOKENS=3200    # 안전 기본값 (티어 사용 시 크게 영향 없음)

# 티어별(권장): Quick=가성비 점검, Deep=최종 다듬기
PROOFREADING_QUICK_MAX_OUTPUT_TOKENS=2400
PROOFREADING_DEEP_MAX_OUTPUT_TOKENS=4200

# 재시도
PROOFREADING_RESPONSES_MAX_RETRIES=3

PROOFREADING_MODEL_FALLBACK=gpt-5-mini
PROOFREADING_FALLBACK_MAX_OUTPUT_TOKENS=3200

# 품질 담당 모델
LITERARY_QA_MODEL=gpt-5-mini
LITERARY_QA_MODEL_VERBOSITY=low # "low" | "medium" | "high"
LITERARY_QA_MODEL_REASONING_EFFORT=low # "low" | "medium" | "high"
LITERARY_QA_MAX_OUTPUT_TOKENS=16000
LITERARY_QA_MAX_OUTPUT_TOKENS_CAP=24000

# .HWP 파일 처리용 Python 경로
PYTHON_BIN=python3

# eBook 책표지 생성형 모델
GOOGLE_CLIENT_ID=your-google-client-id
GOOGLE_CLIENT_SECRET=your-google-client-secret
# GOOGLE_CALLBACK_URL=http://localhost:8080/api/auth/google/callback
# OAUTH_SUCCESS_REDIRECT=http://localhost:5174/oauth/callback

GEMINI_API_KEY=your-gemini-api-key
COVER_STORAGE_DIR=storage/covers
COVER_SVG_ARCHIVE_DIR=storage/covers/archive
EBOOK_STORAGE_DIR=storage/ebooks

# Redis URL for BullMQ
REDIS_URL=redis://127.0.0.1:6379
