// server/agents/qualityAgent.ts
// OpenAI APIë¥¼ í™œìš©í•´ ë²ˆì—­ í’ˆì§ˆ(ë‹¨ì¼ ë²ˆì—­ í‰ê°€)ì„ ìˆ˜í–‰í•˜ëŠ” ëª¨ë“ˆ
// Fastify ë¼ìš°íŠ¸ì—ì„œ í˜¸ì¶œí•´ ì‚¬ìš©í•©ë‹ˆë‹¤.

import OpenAI from "openai";
import { z } from "zod";

import { SHARED_TRANSLATION_GUIDELINES } from "./prompts/sharedGuidelines";

// ----------------------------- íƒ€ì… ì •ì˜ -----------------------------

// ì •ëŸ‰ í‰ê°€ í•­ëª© í‚¤
export type QuantKeys =
  | "Fidelity" // ì›ì‘ ì˜ë¯¸ ì¶©ì‹¤ì„±
  | "Fluency" // ì˜ì–´ ë¬¸ì¥ ìœ ì°½ì„±
  | "Literary Style" // ë¬¸ì²´/í†¤ ì¬í˜„
  | "Cultural Resonance" // ë¬¸í™”ì  ê³µëª…
  | "Creative Autonomy"; // ì°½ì˜ì  ììœ¨ì„±

// ê° í•­ëª©ë³„ ì ìˆ˜ì™€ ì½”ë©˜íŠ¸ (í•œ/ì˜ ì§€ì›)
export type QuantScores = Record<
  QuantKeys,
  { score: number; commentary: { ko: string; en: string } }
>;

// ìµœì¢… í‰ê°€ ê²°ê³¼ êµ¬ì¡°
export interface FinalEvaluation {
  overallScore: number; // ì „ì²´ í‰ê·  ì ìˆ˜
  qualitative: {
    emotionalDepth: { ko: string; en: string }; // ì •ì„± í‰ê°€: ê°ì • ê¹Šì´
    vividness: { ko: string; en: string }; // ë¬˜ì‚¬ì˜ ìƒìƒí•¨
    metaphors: { ko: string; en: string }; // ë¹„ìœ /ì€ìœ  í™œìš©
    literaryValue: { ko: string; en: string }; // ë¬¸í•™ì  ê°€ì¹˜
  };
  quantitative: QuantScores; // ì •ëŸ‰ í‰ê°€ ê²°ê³¼
  meta: {
    model: string; // ì‚¬ìš©í•œ ëª¨ë¸ëª…
    chunks: number; // ì²­í¬ ê°œìˆ˜
    chunkSize: number; // ì²­í¬ ìµœëŒ€ ê¸¸ì´
    overlap: number; // ì²­í¬ ê²¹ì¹¨ í¬ê¸°
    requestIds: string[]; // OpenAI API ìš”ì²­ IDë“¤ (ë””ë²„ê¹…ìš©)
    tokens?: {
      input: number;
      output: number;
      total: number;
    };
  };
}

// í‰ê°€ í•¨ìˆ˜ ì…ë ¥ê°’
export interface EvaluateParams {
  source: string; // ì›ì‘ (í•œê¸€)
  translated: string; // ë²ˆì—­ë¬¸ (ì˜ì–´)
  authorIntention?: string; // ì‘ê°€ ì˜ë„/ë²ˆì—­ ë°©í–¥ (ì„ íƒ)
  model?: string; // OpenAI ëª¨ë¸ëª… (ê¸°ë³¸ gpt-4.1)
  maxCharsPerChunk?: number; // ì²­í¬ ìµœëŒ€ ê¸¸ì´ (ê¸°ë³¸ 8000ì)
  overlap?: number; // ì²­í¬ ê°„ ê²¹ì¹¨ ê¸¸ì´ (ê¸°ë³¸ 400ì)
  strict?: boolean; // ê²€ì¦ ì—¬ë¶€ (ê¸°ë³¸ true)
}

// ----------------------------- OpenAI Client -----------------------------

const DEFAULT_LITERARY_MODEL = process.env.LITERARY_QA_MODEL || "gpt-4o-mini";

const client = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: ëª¨ë¸ì—ê²Œ "ì´ êµ¬ì¡°ë¡œ JSONë§Œ ë°˜í™˜í•˜ë¼"ê³  ê°•ì œ
const SYSTEM_PROMPT = `
You are a professional literary translator and editor.
Evaluate a single English translation of a Korean literary source, producing BOTH numeric scores (0â€“100) and concise literary commentary in BOTH Korean and English.

Follow this fixed output schema (JSON). Do NOT include any text outside JSON.
Schema:
{
  "overallScore": number,
  "qualitative": {
    "emotionalDepth": { "ko": string, "en": string },
    "vividness": { "ko": string, "en": string },
    "metaphors": { "ko": string, "en": string },
    "literaryValue": { "ko": string, "en": string }
  },
  "quantitative": {
    "Fidelity":         { "score": number, "commentary": { "ko": string, "en": string } },
    "Fluency":          { "score": number, "commentary": { "ko": string, "en": string } },
    "Literary Style":   { "score": number, "commentary": { "ko": string, "en": string } },
    "Cultural Resonance": { "score": number, "commentary": { "ko": string, "en": string } },
    "Creative Autonomy":  { "score": number, "commentary": { "ko": string, "en": string } }
  }
}

Apply these shared evaluation guidelines consistently:
${SHARED_TRANSLATION_GUIDELINES}

Additional instructions:
- Korean commentary should be natural and professional Korean.
- English commentary should be natural and professional English.
- Keep both versions concise but informative and ensure they convey the same meaning.
`;

// ----------------------------- ì²­í¬ ë¶„í•  í•¨ìˆ˜ -----------------------------

// ê¸´ í…ìŠ¤íŠ¸ë¥¼ ì¼ì • í¬ê¸° ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ëŠ” í•¨ìˆ˜ (ë¬¸ë‹¨ ìš°ì„  â†’ ë¬¸ì¥ ë¶„ë¦¬)
// overlap ì˜µì…˜ìœ¼ë¡œ ì• ì²­í¬ ê¼¬ë¦¬ë¥¼ ë¶™ì—¬ ë§¥ë½ ë³´ì¡´
function splitIntoChunks(text: string, target = 8000, overlap = 400): string[] {
  if (text.length <= target) return [text];
  const paras = text.split(/\n{2,}/g); // ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ ë¨¼ì € ë¶„ë¦¬
  const chunks: string[] = [];
  let buf: string[] = [];
  let curLen = 0;

  const flush = () => {
    if (!buf.length) return;
    chunks.push(buf.join("\n\n"));
    buf = [];
    curLen = 0;
  };

  for (const p of paras) {
    const plus = (curLen ? 2 : 0) + p.length;
    if (curLen + plus <= target) {
      buf.push(p);
      curLen += plus;
    } else if (p.length > target) {
      // ë¬¸ë‹¨ì´ ë„ˆë¬´ ê¸¸ë©´ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë‹¤ì‹œ ë¶„ë¦¬
      const sens = p.split(/(?<=[.!?])\s+/);
      let sbuf: string[] = [];
      let slen = 0;
      const sflush = () => {
        if (!sbuf.length) return;
        chunks.push(sbuf.join(" "));
        sbuf = [];
        slen = 0;
      };
      for (const s of sens) {
        const add = (slen ? 1 : 0) + s.length;
        if (slen + add <= target) {
          sbuf.push(s);
          slen += add;
        } else {
          sflush();
          sbuf.push(s);
          slen = s.length;
        }
      }
      sflush();
      flush();
    } else {
      flush();
      buf.push(p);
      curLen = p.length;
    }
  }
  flush();

  // overlap ì²˜ë¦¬: ì´ì „ ì²­í¬ì˜ ê¼¬ë¦¬ë¥¼ ë¶™ì—¬ ë§¥ë½ ìœ ì§€
  if (overlap > 0 && chunks.length > 1) {
    const withOverlap: string[] = [];
    for (let i = 0; i < chunks.length; i++) {
      if (i === 0) withOverlap.push(chunks[i]);
      else withOverlap.push(chunks[i - 1].slice(-overlap) + chunks[i]);
    }
    return withOverlap;
  }
  return chunks;
}

// ë²ˆì—­ë¬¸ì€ ì›ì‘ê³¼ ê¸¸ì´ê°€ ë‹¤ë¥´ë¯€ë¡œ, ê°œìˆ˜ ë§ì¶° ë¹„ìœ¨ë¡œ ìë¥´ê¸°
function proportionalSliceByCount(text: string, count: number): string[] {
  if (count <= 1) return [text];
  const len = text.length;
  const out: string[] = [];
  for (let i = 0; i < count; i++) {
    const s = Math.floor((i / count) * len);
    const e = Math.floor(((i + 1) / count) * len);
    out.push(text.slice(s, e));
  }
  return out;
}

// ----------------------------- OpenAI í˜¸ì¶œ -----------------------------

// ê¸°ëŒ€í•˜ëŠ” JSON êµ¬ì¡° ì •ì˜ (Zodë¡œ íŒŒì‹± ê²€ì¦)
const EvalJson = z.object({
  overallScore: z.number(),
  qualitative: z.object({
    emotionalDepth: z.object({ ko: z.string(), en: z.string() }),
    vividness: z.object({ ko: z.string(), en: z.string() }),
    metaphors: z.object({ ko: z.string(), en: z.string() }),
    literaryValue: z.object({ ko: z.string(), en: z.string() }),
  }),
  quantitative: z.object({
    Fidelity: z.object({
      score: z.number(),
      commentary: z.object({ ko: z.string(), en: z.string() }),
    }),
    Fluency: z.object({
      score: z.number(),
      commentary: z.object({ ko: z.string(), en: z.string() }),
    }),
    "Literary Style": z.object({
      score: z.number(),
      commentary: z.object({ ko: z.string(), en: z.string() }),
    }),
    "Cultural Resonance": z.object({
      score: z.number(),
      commentary: z.object({ ko: z.string(), en: z.string() }),
    }),
    "Creative Autonomy": z.object({
      score: z.number(),
      commentary: z.object({ ko: z.string(), en: z.string() }),
    }),
  }),
});

const evalResponseJsonSchema = {
  name: "quality_evaluation_response",
  schema: {
    type: "object",
    additionalProperties: false,
    required: ["overallScore", "qualitative", "quantitative"],
    properties: {
      overallScore: { type: "number" },
      qualitative: {
        type: "object",
        additionalProperties: false,
        required: [
          "emotionalDepth",
          "vividness",
          "metaphors",
          "literaryValue",
        ],
        properties: {
          emotionalDepth: {
            type: "object",
            additionalProperties: false,
            required: ["ko", "en"],
            properties: {
              ko: { type: "string" },
              en: { type: "string" },
            },
          },
          vividness: {
            type: "object",
            additionalProperties: false,
            required: ["ko", "en"],
            properties: {
              ko: { type: "string" },
              en: { type: "string" },
            },
          },
          metaphors: {
            type: "object",
            additionalProperties: false,
            required: ["ko", "en"],
            properties: {
              ko: { type: "string" },
              en: { type: "string" },
            },
          },
          literaryValue: {
            type: "object",
            additionalProperties: false,
            required: ["ko", "en"],
            properties: {
              ko: { type: "string" },
              en: { type: "string" },
            },
          },
        },
      },
      quantitative: {
        type: "object",
        additionalProperties: false,
        required: [
          "Fidelity",
          "Fluency",
          "Literary Style",
          "Cultural Resonance",
          "Creative Autonomy",
        ],
        properties: {
          Fidelity: {
            type: "object",
            additionalProperties: false,
            required: ["score", "commentary"],
            properties: {
              score: { type: "number" },
              commentary: {
                type: "object",
                additionalProperties: false,
                required: ["ko", "en"],
                properties: {
                  ko: { type: "string" },
                  en: { type: "string" },
                },
              },
            },
          },
          Fluency: {
            type: "object",
            additionalProperties: false,
            required: ["score", "commentary"],
            properties: {
              score: { type: "number" },
              commentary: {
                type: "object",
                additionalProperties: false,
                required: ["ko", "en"],
                properties: {
                  ko: { type: "string" },
                  en: { type: "string" },
                },
              },
            },
          },
          "Literary Style": {
            type: "object",
            additionalProperties: false,
            required: ["score", "commentary"],
            properties: {
              score: { type: "number" },
              commentary: {
                type: "object",
                additionalProperties: false,
                required: ["ko", "en"],
                properties: {
                  ko: { type: "string" },
                  en: { type: "string" },
                },
              },
            },
          },
          "Cultural Resonance": {
            type: "object",
            additionalProperties: false,
            required: ["score", "commentary"],
            properties: {
              score: { type: "number" },
              commentary: {
                type: "object",
                additionalProperties: false,
                required: ["ko", "en"],
                properties: {
                  ko: { type: "string" },
                  en: { type: "string" },
                },
              },
            },
          },
          "Creative Autonomy": {
            type: "object",
            additionalProperties: false,
            required: ["score", "commentary"],
            properties: {
              score: { type: "number" },
              commentary: {
                type: "object",
                additionalProperties: false,
                required: ["ko", "en"],
                properties: {
                  ko: { type: "string" },
                  en: { type: "string" },
                },
              },
            },
          },
        },
      },
    },
  },
};

// ë‹¨ì¼ ì²­í¬ í‰ê°€ ìš”ì²­
async function evalChunk(params: {
  model: string;
  sourceChunk: string;
  translatedChunk: string;
  authorIntention?: string;
  attempt?: number;
}): Promise<{
  data: z.infer<typeof EvalJson>;
  requestId?: string;
  usage?: {
    prompt_tokens?: number;
    completion_tokens?: number;
    total_tokens?: number;
  };
}> {
  const {
    model,
    sourceChunk,
    translatedChunk,
    authorIntention,
    attempt = 1,
  } = params;

  const userBlock = [
    `SOURCE_TEXT (Korean):\n${sourceChunk}`,
    `\nTRANSLATED_TEXT (English):\n${translatedChunk}`,
    authorIntention ? `\nAUTHOR_INTENTION:\n${authorIntention}` : "",
    `\nReturn ONLY valid JSON as per schema.`,
  ].join("\n");

  try {
    console.log(
      `ğŸ¤– [QualityAgent] Calling OpenAI with model: ${model}, attempt: ${attempt}`,
    );
    console.log(
      `ğŸ“ [QualityAgent] Source chunk length: ${sourceChunk.length}, Translated chunk length: ${translatedChunk.length}`,
    );

    const resp = await client.chat.completions.create({
      model,
      messages: [
        { role: "system", content: SYSTEM_PROMPT },
        { role: "user", content: userBlock },
      ],
      temperature: 0.1,
      max_tokens: 3000,
      response_format: {
        type: "json_schema",
        json_schema: evalResponseJsonSchema,
      },
    });

    const requestId = resp.id;
    const text = resp.choices[0]?.message?.content || "";

    console.log(
      `ğŸ“¤ [QualityAgent] OpenAI response received, request ID: ${requestId}`,
    );
    console.log(`ğŸ“„ [QualityAgent] Raw response length: ${text?.length || 0}`);

    try {
      const jsonData = JSON.parse(text);
      console.log(`âœ… [QualityAgent] JSON parsing successful`);

      const parsed = EvalJson.parse(jsonData); // JSON íŒŒì‹± & ê²€ì¦
      console.log(
        `âœ… [QualityAgent] Zod validation successful, overall score: ${parsed.overallScore}`,
      );

      return { data: parsed, requestId, usage: resp.usage };
    } catch (parseError) {
      console.error(`âŒ [QualityAgent] JSON/Zod parsing failed:`, parseError);
      console.error(
        `âŒ [QualityAgent] Raw response text:`,
        text?.substring(0, 500),
      );
      throw parseError;
    }
  } catch (err) {
    console.error(
      `ğŸ’¥ [QualityAgent] OpenAI call failed (attempt ${attempt}):`,
      err,
    );

    // ì‹¤íŒ¨ ì‹œ ìµœëŒ€ 3íšŒ ì¬ì‹œë„ (ì§€ìˆ˜ ë°±ì˜¤í”„)
    if (attempt < 3) {
      console.log(`ğŸ”„ [QualityAgent] Retrying in ${600 * attempt}ms...`);
      await new Promise((r) => setTimeout(r, 600 * attempt));
      return evalChunk({ ...params, attempt: attempt + 1 });
    }
    console.error(`âŒ [QualityAgent] All retry attempts failed`);
    throw err;
  }
}

// ----------------------------- ì§‘ê³„ í•¨ìˆ˜ -----------------------------

const avg = (ns: number[]) =>
  Math.round(ns.reduce((a, b) => a + b, 0) / Math.max(1, ns.length));

const merge = (parts: string[], limit = 4) =>
  parts
    .map((s) => s.trim())
    .filter(Boolean)
    .slice(0, limit)
    .join(" ");

// Merge function for bilingual content
// Accept inputs where ko/en may be optional coming from partial chunk results
const mergeBilingual = (
  parts: Array<{ ko?: string; en?: string }>,
  limit = 4,
) => ({
  ko: merge(
    parts.map((p: any) => p.ko || ""),
    limit,
  ),
  en: merge(
    parts.map((p: any) => p.en || ""),
    limit,
  ),
});

// ----------------------------- ìµœì¢… í‰ê°€ í•¨ìˆ˜ -----------------------------

export async function evaluateQuality({
  source,
  translated,
  authorIntention,
  model = DEFAULT_LITERARY_MODEL,
  maxCharsPerChunk = 8000,
  overlap = 400,
  strict = true,
}: EvaluateParams): Promise<FinalEvaluation> {
  console.log("ğŸ¯ [QualityAgent] Starting quality evaluation");
  console.log(`ğŸ“Š [QualityAgent] Parameters:`, {
    sourceLength: source.length,
    translatedLength: translated.length,
    hasAuthorIntention: !!authorIntention,
    model,
    maxCharsPerChunk,
    overlap,
  });

  if (!process.env.OPENAI_API_KEY) {
    console.error("âŒ [QualityAgent] OPENAI_API_KEY is not set");
    throw new Error("OPENAI_API_KEY is not set.");
  }

  // 1) ì›ì‘ê³¼ ë²ˆì—­ë¬¸ì„ ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í• 
  console.log("âœ‚ï¸ [QualityAgent] Splitting text into chunks...");
  const sChunks = splitIntoChunks(source, maxCharsPerChunk, overlap);
  const tChunks = proportionalSliceByCount(translated, sChunks.length);

  console.log(`ğŸ“‘ [QualityAgent] Created ${sChunks.length} chunks`);

  // 2) ê° ì²­í¬ë³„ë¡œ í‰ê°€ ìš”ì²­
  console.log("ğŸ”„ [QualityAgent] Starting chunk evaluation...");
  const per: z.infer<typeof EvalJson>[] = [];
  const reqIds: string[] = [];
  let totalPromptTokens = 0;
  let totalCompletionTokens = 0;

  for (let i = 0; i < sChunks.length; i++) {
    const { data, requestId, usage } = await evalChunk({
      model,
      sourceChunk: sChunks[i],
      translatedChunk: tChunks[i] ?? "",
      authorIntention,
    });
    per.push(data);
    if (requestId) reqIds.push(requestId);
    if (usage) {
      totalPromptTokens += usage.prompt_tokens ?? 0;
      totalCompletionTokens += usage.completion_tokens ?? 0;
    }
  }

  // 3) ì •ëŸ‰ ì ìˆ˜ í‰ê·  + ì •ì„± ì½”ë©˜íŠ¸ í•©ì„±
  const keys: QuantKeys[] = [
    "Fidelity",
    "Fluency",
    "Literary Style",
    "Cultural Resonance",
    "Creative Autonomy",
  ];

  const quantitative = Object.fromEntries(
    keys.map((k) => {
      const scores = per.map((p) => p.quantitative[k].score);
      const coms = per.map((p) => p.quantitative[k].commentary);
      return [k, { score: avg(scores), commentary: mergeBilingual(coms, 2) }];
    }),
  ) as QuantScores;

  const overallScore = avg(keys.map((k) => quantitative[k].score));

  const qualitative = {
    emotionalDepth: mergeBilingual(
      per.map((p) => p.qualitative.emotionalDepth),
    ),
    vividness: mergeBilingual(per.map((p) => p.qualitative.vividness)),
    metaphors: mergeBilingual(per.map((p) => p.qualitative.metaphors)),
    literaryValue: mergeBilingual(per.map((p) => p.qualitative.literaryValue)),
  };

  // 4) ìµœì¢… ê²°ê³¼ ë°˜í™˜
  console.log("ğŸ‰ [QualityAgent] Quality evaluation completed successfully");
  console.log(`ğŸ“Š [QualityAgent] Final result:`, {
    overallScore,
    chunksProcessed: sChunks.length,
    requestIds: reqIds.length,
  });

  return {
    overallScore,
    qualitative,
    quantitative,
    meta: {
      model,
      chunks: sChunks.length,
      chunkSize: maxCharsPerChunk,
      overlap,
      requestIds: reqIds,
      tokens: {
        input: totalPromptTokens,
        output: totalCompletionTokens,
        total: totalPromptTokens + totalCompletionTokens,
      },
    },
  };
}
