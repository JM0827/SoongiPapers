# 원문 처리 프로세스 (Origin Pipeline)

## 1. Purpose & Scope

- 업로드된 원문을 정규화하고 프로젝트 컨텍스트(프로파일, 메모리)를 생성하는 전체 플로우를 다룬다.
- Task/Decision Manager(TDM)은 추출 및 DocumentProfile 분석까지의 워크플로우를 조율한다.
- Baseline/Data Manager(BDM)은 Mongo/Postgres 스냅샷과 Project Memory를 최신 상태로 유지해 번역·교정·품질 단계가 같은 기준을 사용하도록 한다.

## 2. Trigger & Entry Points

- `PUT /api/projects/:projectId/origin` (멀티파트 파일 + JSON 텍스트 업로드). 인증 및 요금제 확인 후 처리 (`server/index.ts:969-1196`).
- `PUT /api/projects/:projectId/origin` with JSON `{ content }` 경로는 에디터에서 직접 원문을 붙여넣는 경우 사용된다.
- `POST /api/projects/:projectId/origin/reanalyze` 는 이미 저장된 원문에 대해 DocumentProfile 재분석만 실행한다 (`server/index.ts:2056-2105`).
- 장애 조건: 파일 누락, 10MB 초과, 미지원 확장자, 추출 실패, 비문자열 content 등은 4xx/5xx로 거절된다 (`server/services/origin/extractor.ts:21-238`).

## 3. Environment & LLM Configuration (.env)

| Variable                              | Default      | Purpose                        | Notes                                                   |
| ------------------------------------- | ------------ | ------------------------------ | ------------------------------------------------------- |
| `PROFILE_AGENT_MODEL`                 | `gpt-5-mini` | DocumentProfile 분석 기본 모델 | 운영 환경에서 `gpt-5` 로 오버라이드하여 고품질 유지 중. |
| `PROFILE_AGENT_VALIDATION_MODEL`      | `gpt-5-mini` | 2차 검증/재시도 모델           | 모델 호출 실패·JSON 오류 시 fallback.                   |
| `PROFILE_AGENT_VERBOSITY`             | `medium`     | Responses `text.verbosity`     | `low/medium/high`.                                      |
| `PROFILE_AGENT_REASONING_EFFORT`      | `medium`     | Responses `reasoning.effort`   | `minimal/low/medium/high`.                              |
| `PROFILE_AGENT_MAX_OUTPUT_TOKENS`     | `1600`       | 초기 `max_output_tokens`       | truncation 시 1.5~2배 증액. 상한은 아래 CAP.            |
| `PROFILE_AGENT_MAX_OUTPUT_TOKENS_CAP` | `4800`       | 토큰 상한                      | CAP 도달 시 실패 처리.                                  |
| `PROFILE_AGENT_CONTEXT_CHAR_LIMIT`    | `20000`      | 입력 자르기 기준               | 초과 텍스트는 균등 샘플링 후 LLM에 전달.                |

## 4. Workflow Orchestration (TDM)

- 업로드 성공 시 `extractOriginFromUpload` 가 확장자별 추출기를 선택하고 정규화한다.
- Postgres `translationprojects.origin_file` 업데이트 후 Mongo `origin_files`/`translation_files`에 메타와 텍스트를 업서트 한다.
- `enqueueProfileAnalysisJob` 이 `jobs` 테이블에 `type='profile'` 작업을 추가하고, `startProfileWorker` 가 2.5초 주기로 폴링하며 처리한다.
- 워커는 원문/번역/프로젝트 메모를 로드 → LLM 분석 호출 → 결과를 DocumentProfile + Project Memory에 반영하고 토큰 사용량을 집계한다.

## 5. LLM Invocation Strategy & Safeguards

- OpenAI Responses API + JSON Schema(`document_profile_analysis`)를 사용해 구조화된 요약/독자 포인트/번역 노트를 강제한다.
- `safeExtractOpenAIResponse`가 스트리밍 응답을 안전하게 파싱하고, JSON 파싱 실패 시 즉시 재시도한다 (`server/services/llm.ts:37-95`).
- truncation(`openai_response_incomplete`) 발생 시 `max_output_tokens`를 최대 CAP까지 기하급수적으로 증가시키며 재호출한다.
- 모델 오류/429 발생 시 fallback 모델을 사용하며, 재시도 횟수/토큰 예산/트렁케이션 여부를 메타에 기록해 성능 추적이 가능하다.

## 6. Data Persistence & BDM Responsibilities

- Mongo `origin_files`, `translation_files` 에 원문 텍스트와 통계를 보전한다.
- Mongo `DocumentProfile` 컬렉션과 Project Memory는 번역·교정·품질 단계가 공유하는 캐릭터/용어/노트 데이터를 유지한다 (`server/index.ts:3306-3368`, `server/index.ts:4268-4352`).
- Postgres `jobs`/`translationprojects` 는 작업 상태와 타임스탬프를 업데이트하여 UI와 관리페이지가 최신 정보를 조회할 수 있게 한다.

## 7. UX Integration & Status Delivery

- 업로드 직후 응답에 정규화된 텍스트/통계를 포함해 에디터가 즉시 미리보기를 보여준다.
- `useProjectContext`는 `origin-uploaded` → `origin-analysis-pending` → `origin-ready` 상태로 갱신하며, Left Sidebar/타임라인에 표시된다 (`web/src/hooks/useProjectContext.ts:200-284`).
- DocumentProfile와 번역 노트는 Right Panel의 요약/메모 섹션에서 사용된다 (`web/src/components/layout/RightPanel.tsx`).

## 8. Reliability & Performance Controls

- 추출기는 확장자별로 최적화된 라이브러리를 사용하며, Python 기반 HWP 추출은 30초 타임아웃과 친절한 에러 메시지를 갖는다.
- 파일 크기/확장자/텍스트 검증으로 불안정한 업로드를 초기에 차단한다.
- 프로파일 워커는 단일 실행 실패 시 다음 작업으로 넘어가며, 재시도 중단 시에도 작업 상태를 `failed` 로 명확히 남겨 후속 수동 조치가 가능하다.
- LLM 호출 입력은 20k자 제한을 적용해 모델 안정성과 응답 시간을 보장한다.

## 9. Monitoring & Alerting

- `[ORIGIN]`, `[PROFILE_AGENT]` 로그가 업로드/추출/LLM 단계별로 출력되며, CloudWatch/Datadog 대시보드에서 추적한다.
- Postgres `jobs` 테이블은 상태(`queued/running/done/failed`)와 오류 메시지를 저장해 Admin UI에서 확인할 수 있다.
- `recordTokenUsage`는 `event_type='profile'` 로 토큰 소비를 집계하여 비용 스파이크를 감시한다 (`server/index.ts:3337-3357`).

## 10. Risks & Next Actions

- 초장문의 원문은 20k자 샘플링에 의해 맥락이 손실될 수 있으므로 단계적 페이징 전략을 검토한다.
- HWP 추출 안정성은 외부 Python 의존성에 좌우되므로, 장애율 모니터링과 캐시 전략이 필요하다.
- DocumentProfile 재분석이 잦은 프로젝트의 큐 지연을 줄이기 위해 워커 동시성/우선순위 튜닝을 계획한다.
