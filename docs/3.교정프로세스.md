# 교정 프로세스 (Proofreading Pipeline)

## 1. Purpose & Scope
- 번역본을 GPT-5 기반 교정기로 검토하여 문법/스타일 이슈를 구조화된 리포트로 생성한다.
- TDM은 `/api/proofread` 요청을 처리하는 Proofreading Agent가 수행하며, 서브피처 실행과 재시도를 관리한다.
- BDM은 Mongo/Postgres 저장소를 통해 교정 리포트·히스토리를 유지하고, Proofread Editor가 동일 데이터를 사용하도록 한다.

## 2. Trigger & Entry Points
- `POST /api/proofread` 가 교정을 시작하며 프로젝트 ID, 번역 Job ID, 워크플로우 라벨을 입력으로 받는다 (`server/agents/proofreading/proofreadingAgent.ts`).
- 클라이언트는 `api.requestProofreading` 으로 NDJSON 스트림을 구독하며 진행 이벤트를 수신한다 (`web/src/services/api.ts:1818-1886`).
- Proofread Editor는 `/api/projects/:projectId/proofread/editor` 및 `/stream` 엔드포인트로 결과/상태를 받아 UI에 반영한다 (`server/routes/proofreadEditor.ts`).

## 3. Environment & LLM Configuration (.env)
| Variable | Default | Purpose | Notes |
| --- | --- | --- | --- |
| `PROOFREADING_MODEL` | `gpt-5` | 교정 기본 모델 | Quick/Deep 티어 모두 동일 시퀀스를 공유한다.
| `PROOFREADING_MODEL_FALLBACK` | `gpt-5-mini` | 모델 fallback | Responses 오류/429 시 사용.
| `PROOFREADING_MAX_OUTPUT_TOKENS` | unset | 전체 토큰 상한 | 미설정 시 Quick/Deep 기본값(800/1200)을 사용.
| `PROOFREAD_QUICK_MAX_OUTPUT_TOKENS` | `800` | Quick 단계 초기 토큰 | truncation 시 CAP (`PROOFREADING_MAX_OUTPUT_TOKENS_CAP`, 기본 2400)까지 증가.
| `PROOFREAD_DEEP_MAX_OUTPUT_TOKENS` | `1200` | Deep 단계 초기 토큰 | 상동.
| `PROOFREADING_MAX_OUTPUT_TOKENS_CAP` | `2400` | 토큰 CAP | 글로벌 또는 티어별 값이 없다면 적용.
| `PROOFREADING_VERBOSITY` | unset | 기본 Responses `text.verbosity` | Quick/Deep 개별 값(`PROOFREAD_QUICK_VERBOSITY`, `PROOFREAD_DEEP_VERBOSITY`) 우선.
| `PROOFREADING_REASONING_EFFORT` | unset | 기본 `reasoning.effort` | Quick/Deep 개별 값(`PROOFREAD_QUICK_EFFORT`, `PROOFREAD_DEEP_EFFORT`) 우선.
| `PROOFREAD_RESPONSES_MAX_RETRIES` | `3` | Responses 재시도 횟수 | truncation/JSON 오류 시 토큰을 올리며 재시도.
| `PROOFREADING_SPEC_PATH` | 내장 spec | 교정 서브피처 구성 파일 경로 | 커스텀 spec 주입 시 사용.
| `VITE_PROOFREAD_HEARTBEAT_MS` | `60000` | 클라이언트 정지 감지 임계값 | Proofread Agent UI에서 stall 여부 판단.

## 4. Workflow Orchestration (TDM)
- Proofreading Agent는 중복 실행을 방지하기 위해 `proofread_runs` 테이블을 조회하고 dedupe 핸드셰이크를 수행한다.
- 서브피처(Grammar, Style 등)는 Spec 정의에 따라 병렬 실행되며, `runGenericWorker` 가 LLM 호출/재시도/토큰 관리 역할을 한다 (`server/agents/proofreading/genericWorker.ts`).
- Quick 티어 완료 후 Deep 티어가 조건부로 실행되고, 최종적으로 Mongo `proofreading_files` 와 Postgres `proofreading_history` 에 기록된다.
- Guard/메모리 컨텍스트는 QA Guard·Project Memory에서 수집해 각 서브피처 입력에 포함된다.

## 5. LLM Invocation Strategy & Safeguards
- OpenAI Responses API + JSON Schema(`proofreading_items_schema_v1`)로 항목 구조를 강제한다.
- truncation 발생 시 토큰 예산을 1.5배씩 늘리고, Verbosity/Effort를 단계적으로 높인다.
- 모델 fallback 시퀀스는 `.env` 설정(`PROOFREADING_MODEL`, `PROOFREADING_MODEL_FALLBACK`)을 따르며, Quick/Deep 각각에서 독립적으로 적용된다.
- Guard 정보(`needs_review`, back-translation 등)를 prompt에 함께 전송해 LLM이 고위험 세그먼트를 우선 검토하도록 한다.

## 6. Data Persistence & BDM Responsibilities
- Mongo `proofreading_files` : Quick/Deep/Final 보고서, 이슈 항목, 번역본 스냅샷 저장.
- Postgres `proofread_runs`, `proofreading_history`, `proofreading_logs` : 런 상태, 이벤트 타임라인, 토큰/모델/재시도 메타 기록.
- Proofread Editor는 Mongo+Postgres 데이터를 조합해 하이라이트, 적용/거부 내역을 유지한다 (`server/routes/proofreadEditor.ts`).

## 7. UX Integration & Status Delivery
- `useProofreadAgent` 는 NDJSON 이벤트(`progress`, `stage`, `tier_complete`, `duplicate`, `complete`, `error`)를 구독해 `useWorkflowStore.proofreading` 상태를 갱신한다 (`web/src/hooks/useProofreadAgent.ts`).
- Left Sidebar/Right Panel Activity Feed가 상태(`queued → running → done/failed`)와 티어별 완료 메시지를 표시한다 (`web/src/components/proofreading/ProofreadActivityFeed.tsx`).
- Proofread Editor 스트림(`/proofread/editor/stream`)은 결과 적용 시 실시간 업데이트를 제공한다 (`web/src/services/api.ts:1889-2058`).

## 8. Reliability & Performance Controls
- dedupe 로직이 동일 번역본에 대한 중복 교정을 차단하거나 기존 결과를 즉시 반환한다.
- `p-limit` 를 통해 서브피처 병렬 실행 수를 제어하고, LLM 장애 시 재시도/모델 fallback 후에도 실패하면 명확한 오류 상태를 남긴다.
- Heartbeat 감시(`VITE_PROOFREAD_HEARTBEAT_MS`)로 워커 정지 시 UI에 정체 경고 표시 및 수동 개입을 유도한다.

## 9. Monitoring & Alerting
- `[PROOFREAD]` 로그와 `proofreading_logs` 테이블에 모델/토큰/시도/에러 코드가 남아 장애 분석이 가능하다.
- Admin `/api/admin/proofreading/logs` 엔드포인트로 최근 실행을 조회하고, 토큰·모델 선택·fallback 여부를 확인한다 (`server/routes/admin.ts`).
- `recordTokenUsage` 는 `event_type='proofread_quick/deep'` 형태로 토큰 소비를 분리해 비용 선호도를 추적한다.

## 10. Risks & Next Actions
- Deep 티어 실행 시간이 길어지는 프로젝트는 사전 필터링/샘플링 전략을 검토해 비용과 지연을 줄여야 한다.
- Spec 변경 시 JSON Schema를 함께 업데이트하지 않으면 Responses 오류가 증가할 수 있으므로 배포 전에 스키마 검증이 필요하다.
- Heartbeat 기반 stall 감지는 네트워크 단절에도 반응하므로, 워커-클라이언트 간 보완용 재연결 로직을 강화할 계획이다.
