# Enhancement Plan: Translation & Proofread Pipelines

## Overview
- **Stability:** Recover automatically from JSON parse failures, truncation, and 429 errors across all pipeline stages.
- **UX:** Surface partial errors as sub-task retrying states while keeping run-level success/failure accurate.
- **Cost/SLA:** Improve perceived turnaround by 2â€“4Ã— and cut excess tokens by 30â€“60Â %.
- **Owner:** Codex (BE/FE). Work is staged in milestones below.

## MilestoneÂ 1 â€” Hotfix (Stability Foundations)
**Acceptance:** Unterminated JSON, truncation, or 429 no longer aborts translation/proofread runs; UI shows `recovering` until retries finish; partial failures never flip the run to failed immediately.

### Server
- Extend `safeExtractOpenAIResponse` (`server/services/llm.ts`) with JSON repair: strip control characters, balance braces/brackets, close missing quotes, record `repairApplied`.
- Update `runResponsesWithRetry` (`server/services/openaiResponses.ts`) so `truncated` only reflects the final response; retry sequence becomes `Ã—1.5` â†’ `Ã—2 (cap)` â†’ fallback model â†’ segment-level retry hook.
- Refactor translation/proofread/quality/profile agents to rely solely on the shared parser (remove manual `JSON.parse`) and to record `jsonRepairApplied` in metadata.
- Introduce reusable NDJSON writer (`server/lib/ndjsonStream.ts`) and adopt it in streaming routes (`server/routes/evaluation.ts`, `server/routes/proofreading.ts`).

### Client
- Add shared NDJSON buffer (`web/src/lib/ndjsonBuffer.ts`) and update `web/src/services/sse.ts` + API streaming callers to use it.
- Redesign workflow store (`web/src/store/workflow.store.ts`) to track `run` (queued/running/recovering/done/failed) + `heartbeatAt`, `willRetry`, `nextRetryDelayMs`, and maintain `subStates` array for per-stage progress.
- Update translation hook (`web/src/hooks/useTranslationAgent.ts`) to drive the new run/sub states, emitting `recovering` and retry metadata for UI.

## MilestoneÂ 2 â€” Hardening & UX (WeekÂ 1)
**Acceptance:** End-to-end throughput improves â‰¥2Ã— on the reference set; retry-induced tokens drop â‰¥30Â %; timeline cards display completed/failed/retrying counts with retry ETA.

### Progress (current)
- âœ… Proofread SSE run_id ì •í•©ì„± í™•ë³´ (handshake ì‹œ `workflow` runId ë°°ì œ, stage/items runId ê¸°ë°˜ ì¬êµ¬ë…)
- âœ… A2/A3 êµì • ì•ˆì •í™” í•µì‹¬ ì™„ë£Œ: heartbeatÂ·ì¬ì—°ê²° ë©”íƒ€ ìˆ˜ì§‘, zero-item run guard, pagination/rest í´ë°± í…ŒìŠ¤íŠ¸
- ğŸ”„ ì‹¤ë°ì´í„° QA ë° ìŠ¤íŠ¸ë¦¼ ë©”íƒ€ ì˜ì†í™”/ëŒ€ì‹œë³´ë“œ ë°˜ì˜ ì§„í–‰ ì˜ˆì • (ìš´ì˜ í™•ì¸ í›„ ë²ˆì—­ íŒŒì´í”„ë¼ì¸ í™•ì¥ìœ¼ë¡œ ì´ì–´ê°)
- ğŸ”œ ê³µí†µ ìŠ¤í‚¤ë§ˆ/í˜ì´ì§•ì„ ë²ˆì—­ íŒŒì´í”„ë¼ì¸ì— í™•ì¥ ì ìš© (A2/A3 ìš´ì˜ ê²€ì¦ ì´í›„ ì°©ìˆ˜)

### Server
- Introduce proofread/translation response v2 schema with range-based evidence only; forbid raw text echoes and shorten keys for lean NDJSON payloads. Update prompts accordingly.
- Add `has_more`/`next_cursor` pagination support to `runGenericWorker` and translation agents, limiting `max_items` per call (default 40 quick / 60 deep); retry paths down-shift token and item caps instead of expanding.
- Switch segmentation to token-based lengths (`segmentOriginText`) interpreting `SEGMENTATION_MAX_SEGMENT_LENGTH_V2` as token cap; target 65â€“75Â % context usage.
- Expand Micro-check guards to auto-retry segments when length/sentence ratios fall outside 0.7â€“1.3; log `retry_reason`.
- Add duplicate sentence cache to reuse prior translations (`services/translation/cache.ts`) and record `cache_hit`.
- Expose `repairApplied` in parser result metadata for telemetry/dashboards.

### Client
- Apply run/sub-state model to proofread & quality hooks (`useProofreadAgent`, `useQualityAgent`), mapping stage/chunk info into consistent recovery badges.
- Timeline cards and Sidebar sections show `completed/failed/retrying` counts, retry countdowns, and recovering badges across all stages.

### Optimization
- Trim prompts via ID references (e.g. `STYLE:sg:123`), reduce overlap to 1â€“2 sentences, raise translation worker concurrency (4â€“8) and run proofread subfeatures in parallel.
- Stand up KPI dashboard for latency (P50/P90), retry-rate (reason), token deltas, cache hit rate.
- Design adaptive chunking (target 700â€“900 chars with 1-sentence overlap) and detectionâ†’revision two-pass flow; stage rollout behind feature flag and apply consistently to translation/proofread/quality.
- Prepare shared retry orchestration that enforces pagination, evidence range mode, and token down-shift across translation/proofread/quality agents.

## MilestoneÂ 3 â€” Performance & Cost (WeekÂ 2)
**Acceptance:** App P50 â‰¤ 35Â s, P90 â‰¤ 60Â s (ChatGPT baseline 15Â s); monthly token cost down â‰¥40Â %.

- Model mix: Draft on `*-mini`, Revise on `gpt-5 (thinking)`; Proof/QA use 10â€“20Â % sampling with anomaly-triggered full reruns.
- Combine draft + light proof for short texts (â‰¤1,200 chars) into single call.
- Optimize runtime IO: reuse OpenAI clients with keep-alive/HTTP2, batch final writes, limit logging to errors, warm tokenization/normalization to avoid cold starts.
- ì¬ì ‘ì† UX ê°•í™”: active run snapshot API (`/workflows/:runId/summary` + `/projects/:id/workflows/active`) ì œê³µ, í´ë¼ì´ì–¸íŠ¸ ì§„ì… ì‹œ ìë™ ì¬êµ¬ë…/ìƒíƒœ ë³µì›.
- SSE heartbeat + í´ë°± ì „ëµì„ ë²ˆì—­/êµì • ê³µí†µìœ¼ë¡œ ì ìš©í•˜ê³ , ë¸Œë¼ìš°ì € ì¬ì—°ê²°/ë‹¤ë¥¸ í´ë¼ì´ì–¸íŠ¸ ì§„ì… ì¼€ì´ìŠ¤ê¹Œì§€ ê²€ì¦.
- ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ í™•ì¥: ë²ˆì—­/êµì • P50/P90, ë‹¤ìš´ì‹œí”„íŠ¸ ë¹„ìœ¨, cache hit-rate, ì¬ì ‘ì† ë³µêµ¬ ì§€í‘œ(ë³µêµ¬ ì‹œê°„, ì‹¤íŒ¨ìœ¨) ë…¸ì¶œ.

## Unified Stage Status Delivery
- Define shared status envelope (`status`, `subStatus`, `heartbeatAt`, `willRetry`, `nextRetryDelayMs`) for origin â†’ translation â†’ proofread â†’ quality.
- Provide `/api/projects/:projectId/stages/status` snapshot endpoint; align translation polling response (`useTranslationAgent`) to use same schema.
- Client (`useProjectContext`, timeline, sidebar) consumes unified run/sub states for every stage, showing consistent badges and retry info.

## Test Matrix
1. **Partial JSON** â€“ inject unterminated JSON and confirm run transitions to `recovering` with retries ending `done`/partial failure.
2. **Truncation** â€“ force `max_output_tokens` exhaustion; verify `Ã—1.5 â†’ Ã—2 â†’ fallback` without losing run context.
3. **Proofread subfailure** â€“ emit subfeature error with `willRetry=true`; timeline remains `recovering`, run finishes.
4. **429** â€“ confirm backoff + segment retry keeps run alive.
5. **Quality sampling** â€“ run sample detection; verify anomaly triggers full rerun and logs detection rate.
6. **Performance baseline** â€“ measure P50/P90 & tokens on small/medium/large docs pre- and post-fixes.

## Ops Visibility
- Extend run logs with `json_repair_count`, `retry_reason` (truncation|json|429), `segment_retry_count`, `cache_hit%`.
- Add dashboard widgets for latency, token usage, retry distribution; highlight recovering vs failure states per stage.

---

This plan reflects the backed-up implementation in `/tmp/plan/` and should be used as the authoritative guide when restoring or continuing work.
